{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5496031746031746\n"
     ]
    }
   ],
   "source": [
    "import pandas_datareader as pdr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df = pdr.get_data_yahoo(\"AAPL\", \"2010-11-01\", \"2020-11-01\")\n",
    "df[\"Diff\"] = df.Close.diff()\n",
    "df[\"SMA_2\"] = df.Close.rolling(2).mean()\n",
    "df[\"Force_Index\"] = df[\"Close\"] * df[\"Volume\"]\n",
    "df[\"y\"] = df[\"Diff\"].apply(lambda x: 1 if x > 0 else 0).shift(-1)\n",
    "df = df.drop(\n",
    "   [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Diff\", \"Adj Close\"],\n",
    "   axis=1,\n",
    ").dropna()\n",
    "# print(df)\n",
    "X = df.drop([\"y\"], axis=1).values\n",
    "y = df[\"y\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X,\n",
    "   y,\n",
    "   test_size=0.2,\n",
    "   shuffle=False,\n",
    ")\n",
    "clf = LogisticRegression()\n",
    "clf.fit(\n",
    "   X_train,\n",
    "   y_train,\n",
    ")\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 2s 1ms/step - loss: 0.6924 - acc: 0.5041\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - acc: 0.5235\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - acc: 0.5178\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - acc: 0.5041\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6912 - acc: 0.5250\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - acc: 0.5264\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - acc: 0.5145\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - acc: 0.5168\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - acc: 0.5361\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6928 - acc: 0.5149\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - acc: 0.5271\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - acc: 0.5100\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - acc: 0.5178\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6914 - acc: 0.5276\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - acc: 0.5199\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - acc: 0.5212\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - acc: 0.5182\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - acc: 0.5214\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6911 - acc: 0.5337\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - acc: 0.5296\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - acc: 0.5556\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - acc: 0.5161\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - acc: 0.5176\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6899 - acc: 0.5413\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6902 - acc: 0.5403\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - acc: 0.5269\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - acc: 0.5216\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6925 - acc: 0.5172\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - acc: 0.5212\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6906 - acc: 0.5336\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6907 - acc: 0.5339\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - acc: 0.5144\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - acc: 0.5176\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - acc: 0.5276\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - acc: 0.5215\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - acc: 0.5096\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6936 - acc: 0.5092\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - acc: 0.5380\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - acc: 0.5162\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6895 - acc: 0.5573\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - acc: 0.5296\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6925 - acc: 0.5243\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6925 - acc: 0.5188\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - acc: 0.5302\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - acc: 0.5163\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - acc: 0.5322\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - acc: 0.5091\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - acc: 0.5163\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6928 - acc: 0.5198\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - acc: 0.5175\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - acc: 0.5290\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - acc: 0.5083\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6937 - acc: 0.5186\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6897 - acc: 0.5470\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - acc: 0.5211\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6931 - acc: 0.5172\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6925 - acc: 0.5205\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6932 - acc: 0.5029\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6912 - acc: 0.5263\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - acc: 0.5158\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6933 - acc: 0.5171\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - acc: 0.5267\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6914 - acc: 0.5315\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - acc: 0.5343\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - acc: 0.5222\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6940 - acc: 0.5072\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6907 - acc: 0.5392\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - acc: 0.5297\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - acc: 0.5242\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6893 - acc: 0.5553\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - acc: 0.5325\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6940 - acc: 0.5123\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - acc: 0.5154\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - acc: 0.5100\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - acc: 0.5262\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - acc: 0.5365\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - acc: 0.5173\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6902 - acc: 0.5456\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - acc: 0.5279\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - acc: 0.5150\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - acc: 0.5202\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6930 - acc: 0.5124\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - acc: 0.5216\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6914 - acc: 0.5332\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - acc: 0.5209\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6911 - acc: 0.5412\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - acc: 0.5352\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6940 - acc: 0.5062\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6926 - acc: 0.5153\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6927 - acc: 0.5175\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - acc: 0.5195\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6897 - acc: 0.5540\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6928 - acc: 0.5250\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6903 - acc: 0.5390\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6940 - acc: 0.5123\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - acc: 0.5225\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6886 - acc: 0.5566\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - acc: 0.5264\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - acc: 0.5290\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - acc: 0.5140\n",
      "0.5178571428571429\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import pandas_datareader as pdr\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pdr.get_data_yahoo(\"AAPL\", \"2010-11-01\", \"2020-11-01\")\n",
    "df[\"Diff\"] = df.Close.diff()\n",
    "df[\"SMA_2\"] = df.Close.rolling(2).mean()\n",
    "df[\"Force_Index\"] = df.Close * df.Volume\n",
    "df[\"y\"] = df[\"Diff\"].apply(lambda x: 1 if x > 0 else 0).shift(-1)\n",
    "df = df.drop(\n",
    "   [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Diff\", \"Adj Close\"],\n",
    "   axis=1,\n",
    ").dropna()\n",
    "# print(df)\n",
    "X = StandardScaler().fit_transform(df.drop([\"y\"], axis=1))\n",
    "y = df[\"y\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X,\n",
    "   y,\n",
    "   test_size=0.2,\n",
    "   shuffle=False,\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(LSTM(2, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model.fit(X_train[:, :, np.newaxis], y_train, epochs=100)\n",
    "y_pred = model.predict(X_test[:, :, np.newaxis])\n",
    "print(accuracy_score(y_test, y_pred > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 1s 2ms/step - loss: 0.6969 - acc: 0.4707\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6946 - acc: 0.4845\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6941 - acc: 0.4849\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - acc: 0.5137\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - acc: 0.5202\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6925 - acc: 0.5214\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - acc: 0.5226\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - acc: 0.5411\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - acc: 0.5292\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6927 - acc: 0.5148\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - acc: 0.5164\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6920 - acc: 0.5258\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6914 - acc: 0.5301\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6901 - acc: 0.5438\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - acc: 0.5296\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - acc: 0.5121\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - acc: 0.5212\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - acc: 0.5341\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6912 - acc: 0.5326\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6924 - acc: 0.5187\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6936 - acc: 0.5055\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - acc: 0.5500\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - acc: 0.5210\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6903 - acc: 0.5351\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - acc: 0.5201\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6925 - acc: 0.5254\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6894 - acc: 0.5473\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - acc: 0.5226\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - acc: 0.5129\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - acc: 0.5260\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6911 - acc: 0.5315\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6894 - acc: 0.5533\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - acc: 0.5212\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - acc: 0.5323\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6895 - acc: 0.5450\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6910 - acc: 0.5310\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - acc: 0.5094\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6937 - acc: 0.5058\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6929 - acc: 0.5147\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6905 - acc: 0.5383\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6913 - acc: 0.5316\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6939 - acc: 0.5076\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6903 - acc: 0.5421\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6923 - acc: 0.5229\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - acc: 0.5299\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6948 - acc: 0.4946\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - acc: 0.5268\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6907 - acc: 0.5361\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6901 - acc: 0.5422\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - acc: 0.5304\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6913 - acc: 0.5269\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - acc: 0.5317\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - acc: 0.5478\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6903 - acc: 0.5338\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6896 - acc: 0.5523\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - acc: 0.5291\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6936 - acc: 0.5066\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - acc: 0.5252\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6928 - acc: 0.5156\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - acc: 0.5248\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6915 - acc: 0.5294\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6920 - acc: 0.5231\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6911 - acc: 0.5252\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6937 - acc: 0.5106\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6907 - acc: 0.5373\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6927 - acc: 0.5186\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - acc: 0.5310\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6923 - acc: 0.5201\n",
      "Epoch 69/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - acc: 0.5264\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6925 - acc: 0.5192\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - acc: 0.5148\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - acc: 0.5362\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6908 - acc: 0.5267\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - acc: 0.5228\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6912 - acc: 0.5338\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6917 - acc: 0.5286\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6920 - acc: 0.5290\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6928 - acc: 0.5132\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6920 - acc: 0.5243\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6917 - acc: 0.5201\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6925 - acc: 0.5264\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6895 - acc: 0.5483\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6920 - acc: 0.5198\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6907 - acc: 0.5414\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6929 - acc: 0.5149\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6934 - acc: 0.5074\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6935 - acc: 0.5139\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6921 - acc: 0.5204\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6905 - acc: 0.5366\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6924 - acc: 0.5210\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6918 - acc: 0.5275\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6926 - acc: 0.5212\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6916 - acc: 0.5275\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6919 - acc: 0.5279\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6922 - acc: 0.5265\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6930 - acc: 0.5154\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6918 - acc: 0.5250\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.6920 - acc: 0.5234\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6915 - acc: 0.5273\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.6925 - acc: 0.5135\n",
      "0.5416666666666666\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, GRU\n",
    "import pandas_datareader as pdr\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pdr.get_data_yahoo(\"AAPL\", \"2010-11-01\", \"2020-11-01\")\n",
    "df[\"Diff\"] = df.Close.diff()\n",
    "df[\"SMA_2\"] = df.Close.rolling(2).mean()\n",
    "df[\"Force_Index\"] = df.Close * df.Volume\n",
    "df[\"y\"] = df[\"Diff\"].apply(lambda x: 1 if x > 0 else 0).shift(-1)\n",
    "df = df.drop(\n",
    "    [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Diff\", \"Adj Close\"],\n",
    "    axis=1,\n",
    ").dropna()\n",
    "# print(df)\n",
    "X = StandardScaler().fit_transform(df.drop([\"y\"], axis=1))\n",
    "y = df[\"y\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    shuffle=False,\n",
    ")\n",
    "model = Sequential()\n",
    "model.add(GRU(2, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model.fit(X_train[:, :, np.newaxis], y_train, epochs=100)\n",
    "y_pred = model.predict(X_test[:, :, np.newaxis])\n",
    "print(accuracy_score(y_test, y_pred > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5396825396825397\n"
     ]
    }
   ],
   "source": [
    "import pandas_datareader as pdr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pdr.get_data_yahoo(\"AAPL\", \"2010-11-01\", \"2020-11-01\")\n",
    "df[\"Diff\"] = df.Close.diff()\n",
    "df[\"SMA_2\"] = df.Close.rolling(2).mean()\n",
    "df[\"Force_Index\"] = df[\"Close\"] * df[\"Volume\"]\n",
    "df[\"y\"] = df[\"Diff\"].apply(lambda x: 1 if x > 0 else 0).shift(-1)\n",
    "df = df.drop(\n",
    "   [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\", \"Diff\", \"Adj Close\"],\n",
    "   axis=1,\n",
    ").dropna()\n",
    "# print(df)\n",
    "X = df.drop([\"y\"], axis=1).values\n",
    "y = df[\"y\"].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "   X,\n",
    "   y,\n",
    "   test_size=0.2,\n",
    "   shuffle=False,\n",
    ")\n",
    "clf = make_pipeline(StandardScaler(), SVC(gamma=\"auto\"))\n",
    "clf.fit(\n",
    "   X_train,\n",
    "   y_train,\n",
    ")\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49360627],\n",
       "       [0.49130118]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ass=model.predict([[[0.86383135],\n",
    "        [0.20081424]],\n",
    "\n",
    "       [[0.90172336],\n",
    "        [0.33039402]]])\n",
    "ass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
